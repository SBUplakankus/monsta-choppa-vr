# Unity VR Template - Systems Documentation

This template implements a modular, event-driven architecture for Unity VR projects using Unity 6.3 LTS, the XR Interaction Toolkit, and OpenXR. Systems communicate through a central manager rather than direct dependencies.

---

## ğŸ§  Core Architecture

### ğŸ® **1. Game Manager & State Control**
The `GameManager` is a persistent singleton that acts as the central nervous system for the entire VR experience.

*   **ğŸ¯ Purpose**: Coordinates all subsystems, manages global game state (Menu, Playing, Paused, GameOver), and provides a single point for system communication.
*   **âš™ï¸ How It Works**:
    *   Uses the **Singleton pattern** to ensure only one instance exists across scene loads.
    *   Implements a **state machine** (`GameState`) to control the logical flow of the application.
    *   Employs an **event-driven architecture**. Systems don't call each other directly; instead, they fire and listen to events (e.g., `OnGameStateChanged`, `OnPauseTriggered`). This keeps systems decoupled and modular.
    *   Acts as a **service locator**. Other systems register themselves with the GameManager and can be retrieved by type, allowing any script to safely access core systems like `InputManager` or `UIManager` without needing a direct object reference.

### ğŸ‘¤ **2. XR Rig & Player Controller**
This system configures and manages the physical VR player in the scene, built on top of Unity's `XROrigin`.

*   **ğŸ¯ Purpose**: Handles player embodiment, camera setup, locomotion, and platform-specific adjustments.
*   **âš™ï¸ How It Works**:
    *   **ğŸ“ Core Setup**: The `XRRigController` manages the `XROrigin` GameObject, which contains the main camera and tracked devices (controllers/hands). It configures the camera's height, floor offset, and tracking origin mode (Floor vs. Device).
    *   **ğŸ“± Platform Detection & Calibration**: At runtime, it detects the active XR device (Meta Quest, PC VR, etc.) and applies specific settingsâ€”like controller offset positions or rendering resolutionâ€”to ensure consistent interaction across platforms.
    *   **ğŸš¶ Locomotion Manager**: A key subsystem that unifies different movement methods:
        *   **ğŸ“ Teleportation**: Uses the `TeleportationProvider` and `TeleportationArea/Anchor` for point-and-move navigation.
        *   **ğŸ”„ Smooth Movement/Snap Turn**: Provides continuous analog stick movement and instantaneous turning, managed through `ActionBasedContinuousMoveProvider` and `ActionBasedSnapTurnProvider`.
        *   The manager ensures only one locomotion mode is active at a time to prevent conflict.

### âœ‹ **3. Input & Interaction System**
This is a layered system that translates raw XR controller/device inputs into meaningful game actions.

*   **ğŸ¯ Purpose**: Abstracts complex input handling, provides a consistent API for gameplay code, and manages VR interactors.
*   **âš™ï¸ How It Works**:
    *   **ğŸ›ï¸ Input Manager**: The `VRInputHandler` creates a layer of abstraction over Unity's Input System. Gameplay scripts listen for high-level actions (e.g., "Grab", "Use", "Menu") instead of checking for specific button presses (e.g., "Grip Button"). This makes input remapping and multi-platform support much easier.
    *   **ğŸ•¹ï¸ Interaction Manager**: Controls the `XRDirectInteractor` and `XRRayInteractor` components. It manages interaction states (e.g., switching from direct grab to a UI ray when pointing at a menu) and handles haptic feedback across different controllers.
    *   **ğŸ¯ Action-Based Architecture**: Built on Unity's `ActionBasedController` and `XRInputModalityManager`, which automatically switches between hand tracking and controller input when the user puts on or takes off their controllers.

### ğŸ§© **4. Object Interaction & Physics**
This system governs how users can grab, manipulate, and throw objects in the virtual world.

*   **ğŸ¯ Purpose**: Provides realistic and satisfying object interaction with proper physics.
*   **âš™ï¸ How It Works**:
    *   **âœ‹ Grab System**: The `GrabbableObject` component uses `XRGrabInteractable` with advanced configurations:
        *   **ğŸ¯ Attachment Points**: Objects snap to predefined grab points on the controller/hand for precise control.
        *   **ğŸ“ Physics vs. Kinematic**: Small objects use kinematic movement for stability, while large/heavy objects use physics-based movement for realism.
        *   **âš¡ Velocity Tracking**: Calculates and applies throw velocity upon release based on controller movement.
    *   **ğŸ¤ Two-Handed Interaction**: Special `TwoHandedGrabbable` script allows for scaled manipulation (grabbing with both hands to rotate and resize objects).

### ğŸ“Š **5. UI & Feedback Systems**
VR-optimized interfaces and user feedback mechanisms.

*   **ğŸ¯ Purpose**: Provides clear, comfortable interaction with in-game interfaces and system feedback.
*   **âš™ï¸ How It Works**:
    *   **ğŸ–¥ï¸ VR Canvas Manager**: All UI uses world-space canvases. The `VRCanvasManager` handles:
        *   **ğŸ‘€ Billboarding**: UI elements automatically rotate to face the player.
        *   **âœ‹ Laser Pointer Interaction**: `XRRayInteractor` with `XRUIInputModule` for menu selection.
        *   **ğŸ“ Comfort Settings**: Manages optimal viewing distance and scale to prevent eye strain.
    *   **ğŸ¨ Visual/ Audio Feedback**:
        *   **ğŸŸ¢ Highlight System**: Outline shaders or material swaps on hover.
        *   **ğŸ“³ Haptic System**: Wraps `XRController.SendHapticImpulse` with standardized intensity/duration curves.
        *   **ğŸ”Š Audio Cues**: Spatial audio feedback for interactions (grab, drop, click).

### ğŸ”§ **6. Utility & Tooling Systems**
Support systems that enhance development workflow and runtime performance.

*   **ğŸ¯ Purpose**: Provides debugging tools, performance monitoring, and quality-of-life features.
*   **âš™ï¸ How It Works**:
    *   **ğŸ› VR Debug Console**: In-VR display of logs, warnings, and performance stats using a world-space canvas.
    *   **âš¡ Performance Monitor**: Tracks and displays FPS, draw calls, and memory usage, with warnings for VR-critical thresholds (e.g., <72 FPS on Quest).
    *   **ğŸ’¾ Save System**: JSON-based persistence for player settings, game progress, and object states.

---

## ğŸ”„ **System Communication Flow**
Hereâ€™s a typical sequence showing how these systems work together:

```mermaid
sequenceDiagram
    participant U as User
    participant I as Input System
    participant G as GameManager
    participant L as Locomotion
    participant A as Audio/Haptics

    U->>I: Presses "Teleport" button
    I->>G: Fires OnTeleportAction event
    G->>L: Calls TeleportManager.Activate()
    L->>A: Requests haptic feedback pulse
    A->>I: Sends haptic impulse to controller
    L->>U: Activates teleportation arc visual
```

---

## ğŸ“ **Project Structure**
```
Assets/
â”œâ”€â”€ ğŸ“‚ Scripts/
â”‚   â”œâ”€â”€ ğŸ“‚ Core/              # GameManager, Singleton, EventSystem
â”‚   â”œâ”€â”€ ğŸ“‚ Player/            # XRRigController, LocomotionManager
â”‚   â”œâ”€â”€ ğŸ“‚ Interaction/       # InputHandler, GrabSystem, Interactables
â”‚   â”œâ”€â”€ ğŸ“‚ UI/                # VRCanvasManager, RadialMenu, HUD
â”‚   â”œâ”€â”€ ğŸ“‚ Systems/           # AudioManager, SaveSystem, SceneLoader
â”‚   â””â”€â”€ ğŸ“‚ Utilities/         # Extensions, DebugTools, Performance
â”œâ”€â”€ ğŸ“‚ Prefabs/
â”‚   â”œâ”€â”€ ğŸ“‚ XR/                # Complete XR Rig variants
â”‚   â”œâ”€â”€ ğŸ“‚ UI/                # VR-ready UI components
â”‚   â””â”€â”€ ğŸ“‚ Interactables/     # Common grab-ready objects
â””â”€â”€ ğŸ“‚ Settings/
    â”œâ”€â”€ ğŸ“‚ Input/             # Input Action Assets
    â”œâ”€â”€ ğŸ“‚ Presets/           # Component configuration presets
    â””â”€â”€ ğŸ“‚ RenderPipeline/    # VR-optimized URP/HDRP settings
```

---

## ğŸš€ **Getting Started with the Code**
To extend this template:

1.  **ğŸ†• Create a new system**: Implement the `IVRSystem` interface and register it with the `GameManager`.
2.  **ğŸ® Add an interactable**: Attach `GrabbableObject` to any GameObject and configure grab points.
3.  **ğŸ›ï¸ Create a new input action**: Add it to the `VRInputActions` asset and listen via `VRInputHandler.OnActionPerformed`.
4.  **ğŸ“± Add platform-specific behavior**: Check `XRRigController.CurrentDevice` and branch your logic.

---

## ğŸ”§ **Key Configuration Points**
*   **Locomotion Preferences**: Set in `LocomotionManager` inspector (default movement type, turn speed, comfort options).
*   **Input Bindings**: Configure in `Assets/Settings/Input/VRInputActions.inputactions`.
*   **Rig Settings**: Per-platform offsets and camera settings in `XRRigController`.
*   **Performance Caps**: Set target FPS and warning thresholds in `PerformanceMonitor`.

This architecture ensures your VR project remains scalable, maintainable, and easy to debug as complexity grows.

---